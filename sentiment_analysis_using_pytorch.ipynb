{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Mounting the google drive to get the images\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "075A-zUuI_Id",
        "outputId": "b5fee8a5-5080-4b9a-bcfe-db7c33fb4643"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking out the data\n",
        "\n",
        "!ls drive/MyDrive/sentiment_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc31OC96JMIO",
        "outputId": "1f7f9e1c-d94f-43b1-a137-55754de8aa34"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels.txt  reviews.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yVdwvyhbrrjg"
      },
      "outputs": [],
      "source": [
        "# Importing libraries and helper functions\n",
        "\n",
        "import torch \n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from string import punctuation\n",
        "from collections import Counter\n",
        "from torch.utils.data import TensorDataset,DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Opening reading and passing into variables both the review and label\n",
        "\n",
        "with open('drive/MyDrive/sentiment_data/reviews.txt','r') as f:\n",
        "  reviews = f.read()\n",
        "\n",
        "with open('drive/MyDrive/sentiment_data/labels.txt','r') as f:\n",
        "  labels = f.read()"
      ],
      "metadata": {
        "id": "INlTpBDfJbtp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking out the label and review\n",
        "\n",
        "print(reviews[:1000])\n",
        "print('===================')\n",
        "print(labels[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvta4UU_JtGs",
        "outputId": "d1f08840-8e82-4692-c10a-60a69e3a999a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turn\n",
            "===================\n",
            "positive\n",
            "negative\n",
            "po\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a word list free from punctuations spaces or new lines\n",
        "\n",
        "reviews = reviews.lower()\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "reviews_split = all_text.split('\\n')\n",
        "all_text = ''.join(reviews_split)\n",
        "\n",
        "words = all_text.split()"
      ],
      "metadata": {
        "id": "zN4HvvqNKL74"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking out some words from our word list\n",
        "\n",
        "words[10:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97jyBhyRKL5v",
        "outputId": "854b446d-ab9e-4009-a2c2-4f1086d63554"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['same',\n",
              " 'time',\n",
              " 'as',\n",
              " 'some',\n",
              " 'other',\n",
              " 'programs',\n",
              " 'about',\n",
              " 'school',\n",
              " 'life',\n",
              " 'such']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Counter gives us each unique words and their number of occurance\n",
        "# Vocab_to_int is a dictionary mapping the words to an intiger\n",
        "# More occuring words are given a smaller intiger value\n",
        "\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts,key=counts.get,reverse=True)\n",
        "vocab_to_int = { word : int_ for int_,word in enumerate(vocab,1)}\n",
        "\n",
        "reviews_ints = []\n",
        "for review in reviews_split:\n",
        "  reviews_ints.append([vocab_to_int[word] for word in review.split()])\n",
        "\n"
      ],
      "metadata": {
        "id": "_RG4uU_AKL1Z"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets see number of unique words an also checkout our tokenized review\n",
        "\n",
        "print('Unique words: ',len(vocab_to_int))\n",
        "print('===================')\n",
        "print('The first tokenized review: \\n', reviews_ints[:1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCouoOu8QJVr",
        "outputId": "1fc817a5-4f2b-4254-b3f9-cab7bfc34518"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words:  74072\n",
            "===================\n",
            "The first tokenized review: \n",
            " [[21025, 308, 6, 3, 1050, 207, 8, 2138, 32, 1, 171, 57, 15, 49, 81, 5785, 44, 382, 110, 140, 15, 5194, 60, 154, 9, 1, 4975, 5852, 475, 71, 5, 260, 12, 21025, 308, 13, 1978, 6, 74, 2395, 5, 613, 73, 6, 5194, 1, 24103, 5, 1983, 10166, 1, 5786, 1499, 36, 51, 66, 204, 145, 67, 1199, 5194, 19869, 1, 37442, 4, 1, 221, 883, 31, 2988, 71, 4, 1, 5787, 10, 686, 2, 67, 1499, 54, 10, 216, 1, 383, 9, 62, 3, 1406, 3686, 783, 5, 3483, 180, 1, 382, 10, 1212, 13583, 32, 308, 3, 349, 341, 2913, 10, 143, 127, 5, 7690, 30, 4, 129, 5194, 1406, 2326, 5, 21025, 308, 10, 528, 12, 109, 1448, 4, 60, 543, 102, 12, 21025, 308, 6, 227, 4146, 48, 3, 2211, 12, 8, 215, 23]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets split the label by new line and change positive to 1 and negative to 0\n",
        "\n",
        "labels_split = labels.split('\\n')\n",
        "encoded_labels =  np.array([1 if label == 'positive' else 0 for label in labels_split])\n",
        "encoded_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8_8SWMeQJTX",
        "outputId": "ec945876-6415-4054-d9d5-84555133435e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 1, 0, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets count number of zero reviews and also the maximum review length\n",
        "\n",
        "review_len = Counter([len(x) for x in reviews_ints])\n",
        "print(f'Zero length reviews: {review_len[0]}')\n",
        "print(f'Maximum review length is: {max(review_len)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLvkQc4MQJQ6",
        "outputId": "4bc88f3f-da7e-466c-e8cf-0dfa9c35e422"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero length reviews: 1\n",
            "Maximum review length is: 2514\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets remove the review with a zero length\n",
        "\n",
        "print('Number of reviews before removing outliers: ' , len(reviews_ints))\n",
        "\n",
        "non_zero_idx = [idx for idx,review in enumerate(reviews_ints) if len(review) != 0 ]\n",
        "reviews_ints = [reviews_ints[idx] for idx in non_zero_idx]\n",
        "encoded_labels = np.array([encoded_labels[idx] for idx in non_zero_idx])\n",
        "\n",
        "print('Number of reviews after removing outliers: ' , len(reviews_ints))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nefjQbypQJOj",
        "outputId": "5e5b194d-ce38-4306-aceb-c58db509d731"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of reviews before removing outliers:  25001\n",
            "Number of reviews after removing outliers:  25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "\n",
        " Our reviews are some with longer characters and others with a shorter\n",
        " So for our model to be robust and working effectively we need to pad it\n",
        " We will trim longer characters greater than seq_len and add lists of 0s\n",
        " to the left for smaller length of characters \n",
        " \n",
        "'''\n",
        "def pad_features(reviews_ints,seq_len):\n",
        "\n",
        "  features = np.zeros((len(reviews_ints),seq_len),dtype=int)\n",
        "  for i , row in enumerate(reviews_ints):\n",
        "    features[i,-len(row):] = np.array(row)[:seq_len]\n",
        "\n",
        "  return features"
      ],
      "metadata": {
        "id": "4nVj8zTMXG5S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a max_sequence length and verifying our function is working well\n",
        "\n",
        "seq_len = 200\n",
        "features = pad_features(reviews_ints,seq_len = seq_len)\n",
        "\n",
        "assert len(features) == len(reviews_ints)\n",
        "assert len(features[0]) == seq_len\n",
        "assert len(features[10]) == seq_len\n",
        "assert len(features[100]) == seq_len\n",
        "assert len(features[10002]) == seq_len\n",
        "\n",
        "''' \n",
        "From the print we can see that we added multiple zeros on the left for padding\n",
        "'''\n",
        " \n",
        "print(features[0,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hok41LQkXxi7",
        "outputId": "c12b4b42-24f4-4943-90d2-4b2f6b040041"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            " 21025   308     6     3  1050   207     8  2138    32     1   171    57\n",
            "    15    49    81  5785    44   382   110   140    15  5194    60   154\n",
            "     9     1  4975  5852   475    71     5   260    12 21025   308    13\n",
            "  1978     6    74  2395     5   613    73     6  5194     1 24103     5\n",
            "  1983 10166     1  5786  1499    36    51    66   204   145    67  1199\n",
            "  5194 19869     1 37442     4     1   221   883    31  2988    71     4\n",
            "     1  5787    10   686     2    67  1499    54    10   216     1   383\n",
            "     9    62     3  1406  3686   783     5  3483   180     1   382    10\n",
            "  1212 13583    32   308     3   349   341  2913    10   143   127     5\n",
            "  7690    30     4   129  5194  1406  2326     5 21025   308    10   528\n",
            "    12   109  1448     4    60   543   102    12 21025   308     6   227\n",
            "  4146    48     3  2211    12     8   215    23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "Train test split:\n",
        "We used 80% of our data for training \n",
        "10% for test and the other 10% for validation\n",
        "\n",
        "'''\n",
        "split_frac = 0.8\n",
        "\n",
        "split_idx = int(len(features) * split_frac)\n",
        "train_x, remaining_x = features[:split_idx], features[split_idx:] \n",
        "train_y, remaining_y = encoded_labels[:split_idx], encoded_labels[split_idx:] \n",
        "\n",
        "test_idx = int(len(remaining_x) * 0.5)\n",
        "val_x,test_x = remaining_x[:test_idx], remaining_x[test_idx:]\n",
        "val_y,test_y = remaining_y[:test_idx], remaining_y[test_idx:]\n",
        "\n",
        "print('\\n Feature shapes: \\n')\n",
        "print(f'Train set: {train_x.shape}\\nTest set: {test_x.shape}\\nValidation set {val_x.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQi2qPnyYgyy",
        "outputId": "baa422a6-bec8-4746-de02-fc06ac80c760"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Feature shapes: \n",
            "\n",
            "Train set: (20000, 200)\n",
            "Test set: (2500, 200)\n",
            "Validation set (2500, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a train_loader,test_loader and val_loader for further modeling\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_x),torch.from_numpy(train_y))\n",
        "val_data = TensorDataset(torch.from_numpy(val_x),torch.from_numpy(val_y))\n",
        "test_data = TensorDataset(torch.from_numpy(test_x),torch.from_numpy(test_y))\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_loader = DataLoader(train_data,shuffle=True,batch_size = batch_size)\n",
        "val_loader = DataLoader(val_data,shuffle=True,batch_size = batch_size)\n",
        "test_loader = DataLoader(test_data,shuffle=True,batch_size = batch_size)"
      ],
      "metadata": {
        "id": "J-yNAxGVYgwr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets sample from our train data and see their shapes if they are correct\n",
        "\n",
        "sample_x,sample_y = next(iter(train_loader))\n",
        "\n",
        "print('Sample input size: ', sample_x.size())\n",
        "print('Sample input: ', sample_x)\n",
        "print('Sample label size: ', sample_y.size())\n",
        "print('Sample label: ', sample_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-7ppg_BYguJ",
        "outputId": "085720e8-65c8-4874-bdfe-8608083acd39"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample input size:  torch.Size([50, 200])\n",
            "Sample input:  tensor([[   0,    0,    0,  ...,  115,    8,  150],\n",
            "        [   0,    0,    0,  ..., 1456,    8,   56],\n",
            "        [   0,    0,    0,  ...,   45,    4,  674],\n",
            "        ...,\n",
            "        [   0,    0,    0,  ...,    2,  442, 2956],\n",
            "        [   0,    0,    0,  ...,  789,    8,   45],\n",
            "        [  10,   55,  742,  ..., 2394,   22,  345]])\n",
            "Sample label size:  torch.Size([50])\n",
            "Sample label:  tensor([0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
            "        1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
            "        1, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking out if there is a GPU available \n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  print('Training on GPU....')\n",
        "else: print('Training on CPU....')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQAQXKfMYgrq",
        "outputId": "3474666e-b826-4d8a-ee28-a4d27b277902"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on GPU....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the RNN model\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "\n",
        "  def __init__(self,vocab_size,output_size,embedding_dim,hidden_dim,\n",
        "               n_layers,drop_prob=0.5):\n",
        "    \n",
        "    # Inheriting from the torch.nn model module\n",
        "\n",
        "    super(SentimentRNN,self).__init__()\n",
        "\n",
        "    # Initializing some parameters for our model\n",
        "\n",
        "    self.output_size = output_size\n",
        "    self.n_layers = n_layers\n",
        "    self.hidden_dim = hidden_dim\n",
        "\n",
        "    '''\n",
        "\n",
        "    Our review has more than 70 thousand words so having a one hot encoding\n",
        "    for these all words will be very time consuming and costy. So the torch\n",
        "    nn method has a good module that will enable us to get a vectorized \n",
        "    representation of our words with simpler dimensions.\n",
        "\n",
        "    Given the vocablary size and embedding dimension we will get an embedding\n",
        "    vector for our vocublary. i.e. all words will be represented by our \n",
        "    embedding vector\n",
        "\n",
        "    '''\n",
        "    self.embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim,hidden_dim,n_layers,dropout=drop_prob,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    # We will have a dropout to decrease overfitting\n",
        "\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    '''\n",
        "    At last we will have a fully connected layer \n",
        "    followed by a sigmoid activation for our final\n",
        "    prediction\n",
        "    '''\n",
        "    self.fc = nn.Linear(hidden_dim,output_size)\n",
        "    self.sig = nn.Sigmoid()\n",
        "\n",
        "\n",
        "  def forward(self,x,hidden):\n",
        "\n",
        "    batch_size = x.size(0)\n",
        "\n",
        "    # .long method changes our tensor into numpy\n",
        "\n",
        "    x = x.long()\n",
        "\n",
        "    embeds = self.embedding(x)\n",
        "    lstm_out,hidden = self.lstm(embeds,hidden)\n",
        "\n",
        "    # Taking only the last part of the lstm ouptput above\n",
        "\n",
        "    lstm_out = lstm_out[:,-1,:]\n",
        "\n",
        "    output = self.dropout(lstm_out)\n",
        "    output = self.fc(output)\n",
        "\n",
        "    sig_out = self.sig(output)\n",
        "\n",
        "    return sig_out,hidden\n",
        "\n",
        "  # A function used to initialize the hidden state for our RNN model\n",
        "  \n",
        "  def init_hidden(self,batch_size):\n",
        "    weight = next(self.parameters()).data\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "    else:\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "\n",
        "    return hidden\n",
        "  \n",
        "  "
      ],
      "metadata": {
        "id": "ABBnBhlUYgpm"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inistantiating the model passing the parameters\n",
        "\n",
        "vocab_size = len(vocab_to_int) + 1\n",
        "\n",
        "# Because it predicts either 1 or 0 for which 1 is postive and 0 negative\n",
        " \n",
        "output_size = 1 \n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentRNN(vocab_size,\n",
        "                   output_size,\n",
        "                   embedding_dim,\n",
        "                   hidden_dim,\n",
        "                   n_layers\n",
        "                   )\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF0g7_nWYgmv",
        "outputId": "b9748437-40a3-461f-a6f6-9bddbb5f4af1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentimentRNN(\n",
            "  (embedding): Embedding(74073, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing a loss function and optimizer\n",
        "\n",
        "lr = 0.01 # Learning rate of 0.01\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(),lr=lr)\n"
      ],
      "metadata": {
        "id": "rEjH5j7sYgkX"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing parameters for trainging\n",
        "\n",
        "epochs = 4\n",
        "counter = 0\n",
        "print_every = 100\n",
        "\n",
        "''' \n",
        "\n",
        "Clip is a parameter that we will use later while we \n",
        "train our model. In our back propagation we may encounter\n",
        "exploding gradient, for that purpose we will clip every \n",
        "gradients more than clip to be clip\n",
        "\n",
        "'''\n",
        "clip = 5 \n",
        "\n",
        "# Check if we are using GPU and if so moving the model to the GPU\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  net.cuda()\n",
        "\n",
        "# Entering into training mode\n",
        "\n",
        "net.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  \n",
        "  # Initializing the hidden state\n",
        "\n",
        "  h = net.init_hidden(batch_size)\n",
        "\n",
        "  # Getting inputs and labels from the train loader\n",
        "\n",
        "  for inputs,labels in train_loader:\n",
        "\n",
        "    counter+=1\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "      inputs,labels = inputs.cuda(),labels.cuda()\n",
        "\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    # Clearing cache for our back propagation\n",
        "\n",
        "    net.zero_grad()\n",
        "\n",
        "    # Feeding forward our input and getting the lstm output\n",
        "\n",
        "    output,h = net(inputs,h)\n",
        "\n",
        "    # Calculating the loss based on our criterion we set before\n",
        "\n",
        "    loss = criterion(output.squeeze(),labels.float())\n",
        "\n",
        "    # Backward propagation \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient clipping to elimnate exploding gradient issue\n",
        "\n",
        "    nn.utils.clip_grad_norm_(net.parameters(),clip)\n",
        "\n",
        "    # Weight updating \n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    # Printing validation result every (print_every) steps\n",
        "\n",
        "    if counter % print_every == 0:\n",
        "\n",
        "      val_h = net.init_hidden(batch_size)\n",
        "\n",
        "      val_losses = []\n",
        "\n",
        "      # Entering the evaluation mode and removing all the dropouts\n",
        "\n",
        "      net.eval()\n",
        "\n",
        "      for inputs,labels in val_loader:\n",
        "        \n",
        "        # Creating a validation hidden state\n",
        "\n",
        "        val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "\n",
        "          inputs,labels = inputs.cuda(),labels.cuda()\n",
        "      \n",
        "        output,val_h = net(inputs,val_h)\n",
        "        val_loss = criterion(output.squeeze(),labels.float())\n",
        "        val_losses.append(val_loss.item())\n",
        "\n",
        "      # Getting back to the training mode after finishing the validation\n",
        "\n",
        "      net.train()\n",
        "\n",
        "      # Printing validation results every (print_every) steps\n",
        "\n",
        "      print('Epoch: {}/{}......'.format(epoch+1,epochs),\n",
        "            'Step: {}.....'.format(counter),\n",
        "            'Loss: {:.6f}'.format(loss.item()),\n",
        "            'Validation loss: {:.6f}'.format(np.mean(val_losses)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rJqkK_DYgfz",
        "outputId": "23eaebd6-a4cc-4842-f06b-55f76d49706a"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/4...... Step: 100..... Loss: 0.249063 Validation loss: 0.641705\n",
            "Epoch: 1/4...... Step: 200..... Loss: 0.546562 Validation loss: 0.673263\n",
            "Epoch: 1/4...... Step: 300..... Loss: 0.315827 Validation loss: 0.616148\n",
            "Epoch: 1/4...... Step: 400..... Loss: 0.523387 Validation loss: 0.870079\n",
            "Epoch: 2/4...... Step: 500..... Loss: 0.461046 Validation loss: 0.735487\n",
            "Epoch: 2/4...... Step: 600..... Loss: 0.602474 Validation loss: 0.615451\n",
            "Epoch: 2/4...... Step: 700..... Loss: 0.430550 Validation loss: 0.671795\n",
            "Epoch: 2/4...... Step: 800..... Loss: 0.510659 Validation loss: 0.569646\n",
            "Epoch: 3/4...... Step: 900..... Loss: 0.478471 Validation loss: 0.618111\n",
            "Epoch: 3/4...... Step: 1000..... Loss: 0.585657 Validation loss: 0.677233\n",
            "Epoch: 3/4...... Step: 1100..... Loss: 0.555066 Validation loss: 0.649515\n",
            "Epoch: 3/4...... Step: 1200..... Loss: 0.641896 Validation loss: 0.674005\n",
            "Epoch: 4/4...... Step: 1300..... Loss: 0.576618 Validation loss: 0.690297\n",
            "Epoch: 4/4...... Step: 1400..... Loss: 0.725539 Validation loss: 0.729718\n",
            "Epoch: 4/4...... Step: 1500..... Loss: 0.634622 Validation loss: 0.659162\n",
            "Epoch: 4/4...... Step: 1600..... Loss: 0.652027 Validation loss: 0.629099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing our model on our test_data\n",
        "\n",
        "test_losses = []\n",
        "num_correct = 0\n",
        "\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "\n",
        "for inputs,labels in test_loader:\n",
        "\n",
        "  h = tuple([each.data for each in h])\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    inputs,labels = inputs.cuda(),labels.cuda()\n",
        "\n",
        "  output,h = net(inputs,h)\n",
        "\n",
        "  test_loss = criterion(output.squeeze(),labels.float())\n",
        "\n",
        "  test_losses.append(test_loss.item())\n",
        "\n",
        "  pred = torch.round(output.squeeze())\n",
        "\n",
        "  # Checking out if the pred and labels match\n",
        "\n",
        "  correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "\n",
        "  if not torch.cuda.is_available():\n",
        "\n",
        "    correct = np.squeeze(correct_tensor.numpy())\n",
        "\n",
        "  else:\n",
        "\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "\n",
        "  # Summing up the results of correct predictions\n",
        "\n",
        "  num_correct += np.sum(correct)\n",
        "\n",
        "'''\n",
        "Calculating the test accuracy by deviding number of correct\n",
        "predictions by the total data set number.\n",
        "'''\n",
        "\n",
        "test_accuracy = num_correct / (len(test_loader.dataset))\n",
        "\n",
        "# Printing the test loss\n",
        "\n",
        "print('Test loss: {:.4f}'.format(np.mean(test_losses)))\n",
        "\n",
        "# Printing the test accuracy\n",
        "\n",
        "print('Test accuracy: {:.4f}'.format(test_accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_147usVYgdb",
        "outputId": "60e93774-194b-4f64-8d86-d958252f9ff8"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.6393\n",
            "Test accuracy: 0.6308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A helper function for tokenizing an input review for testing\n",
        "\n",
        "def tokenize_review(test_review):\n",
        "\n",
        "  test_review = test_review.lower()\n",
        "  test_text = ''.join([c for c in test_review if c not in punctuation])\n",
        "\n",
        "  test_words = test_text.split()\n",
        "\n",
        "  test_ints = []\n",
        "  test_ints.append([vocab_to_int.get(word,0) for word in test_words])\n",
        "\n",
        "  return test_ints\n",
        "\n",
        "# Creating a negative test review for test\n",
        "test_review_neg = 'The worst movie I have seen; acting was terrible and I want my money back.'\n",
        "# Tokenizing the review\n",
        "test_ints = tokenize_review(test_review_neg)\n",
        "print(test_ints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7NISvOlQJMB",
        "outputId": "ca1bbd3d-bd2f-4ab9-c514-809758ca0e3a"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 247, 18, 10, 28, 108, 113, 14, 388, 2, 10, 181, 60, 273, 144]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding the review message\n",
        "\n",
        "seq_len = 200\n",
        "features = pad_features(test_ints,seq_len)\n",
        "features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT-E2TFNxMUI",
        "outputId": "a8cd1bd6-5502-48ba-b799-31ad42cdf030"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   1, 247,  18,  10,  28, 108, 113,  14, 388,   2,\n",
              "         10, 181,  60, 273, 144]])"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing the feature into tensor since we feed tensor to our model\n",
        "\n",
        "feature_tensor = torch.from_numpy(features)\n",
        "print(feature_tensor.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_7_RN2VQJJY",
        "outputId": "8dfea97a-41b5-4f3b-c0cd-39d1dbf8d646"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A helper function for predicting sentiment given a review message\n",
        "\n",
        "def predict(net,test_review,seq_len=200):\n",
        "\n",
        "  # Enetering into evaluation mode and removing all the dropouts\n",
        "\n",
        "  net.eval()\n",
        "\n",
        "  # Tokenize the input message\n",
        "\n",
        "  test_ints = tokenize_review(test_review)\n",
        "\n",
        "  # Padding the input message\n",
        "\n",
        "  seq_len = 200\n",
        "  features = pad_features(test_ints,seq_len)\n",
        "\n",
        "  # Changing features into tensors\n",
        "\n",
        "  feature_tensor = torch.from_numpy(features)\n",
        "\n",
        "  # Creating a batch size form the number of messages\n",
        "\n",
        "  batch_size = feature_tensor.size(0)\n",
        "\n",
        "  h = net.init_hidden(batch_size)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "\n",
        "    feature_tensor = feature_tensor.cuda()\n",
        "\n",
        "  output,h = net(feature_tensor,h)\n",
        "\n",
        "  pred = torch.round(output.squeeze())\n",
        "\n",
        "  print('Prediction value before rounding: {:.6f}'.format(output.item()))\n",
        "\n",
        "  # Printing the result of the prediction\n",
        "  \n",
        "  if(pred.item()==1): print('Positive review')\n",
        "  else: print('Negative review')\n"
      ],
      "metadata": {
        "id": "FxajV1TayZLs"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating lists of reviews for testing\n",
        "\n",
        "positive_reviews = ['Thank you!!',\n",
        "                    'Nice moview',\n",
        "                    'This movie has good acting and best video quality. I loved it.',\n",
        "                    'Good']\n",
        "\n",
        "negative_reviews = ['The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting',\n",
        "                    'Very bad movie!!',\n",
        "                    'Worst movie!!',\n",
        "                    'I hate this movie. It has very bad video quality']"
      ],
      "metadata": {
        "id": "0lO694qNB8Zh"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the postive reviews\n",
        "\n",
        "for review in positive_reviews:\n",
        "  print('\\n================')\n",
        "  print('Result of review:',review)\n",
        "  predict(net,review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bC-_AhUCFX6",
        "outputId": "5bd0d372-e020-4ed9-97cf-0bd34c78be0a"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================\n",
            "Result of review: Thank you!!\n",
            "Prediction value before rounding: 0.578878\n",
            "Positive review\n",
            "\n",
            "================\n",
            "Result of review: Nice moview\n",
            "Prediction value before rounding: 0.502255\n",
            "Positive review\n",
            "\n",
            "================\n",
            "Result of review: This movie has good acting and best video quality. I loved it.\n",
            "Prediction value before rounding: 0.756788\n",
            "Positive review\n",
            "\n",
            "================\n",
            "Result of review: Good\n",
            "Prediction value before rounding: 0.516207\n",
            "Positive review\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the negative reviews\n",
        "\n",
        "for review in negative_reviews:\n",
        "  print('\\n================')\n",
        "  print('Result of review:',review)\n",
        "  predict(net,review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJdrMSkRAmnJ",
        "outputId": "3717c1bc-427a-4465-9048-ababad232e37"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================\n",
            "Result of review: The worst movie I have seen; acting was terrible and I want my money back. This movie had bad acting\n",
            "Prediction value before rounding: 0.081830\n",
            "Negative review\n",
            "\n",
            "================\n",
            "Result of review: Very bad movie!!\n",
            "Prediction value before rounding: 0.428250\n",
            "Negative review\n",
            "\n",
            "================\n",
            "Result of review: Worst movie!!\n",
            "Prediction value before rounding: 0.340143\n",
            "Negative review\n",
            "\n",
            "================\n",
            "Result of review: I hate this movie. It has very bad video quality\n",
            "Prediction value before rounding: 0.252431\n",
            "Negative review\n"
          ]
        }
      ]
    }
  ]
}